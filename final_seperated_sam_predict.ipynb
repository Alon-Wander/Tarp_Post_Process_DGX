{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from skimage.morphology import thin, skeletonize\n",
    "from skimage import measure\n",
    "\n",
    "from segment_anything import sam_model_registry, SamPredictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"vit_h\"\n",
    "device = \"cuda\"\n",
    "sam = sam_model_registry[model_type](checkpoint='/mnt/offline_prod/Alon/transfer/tarp_sam_inference_26_10_25/sam_vit_h_4b8939.pth')\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IOU(bounding_box, img, mask1, mask2, display_images=False, mask1_no_dilate=None):\n",
    "\n",
    "    x,y,w,h = bounding_box\n",
    "    u,d,l,r = y, y + h, x, x + w\n",
    "    \n",
    "    patch1 = mask1[u:d,l:r]\n",
    "    patch2 = mask2[u:d,l:r]\n",
    "    \n",
    "    fp1 = (patch1>0).astype(int)\n",
    "    fp2 = (patch2>0).astype(int)\n",
    "    \n",
    "    union_mask = np.zeros((h,w), np.uint8)\n",
    "    intersect_mask = np.zeros((h,w), np.uint8)\n",
    "    \n",
    "    intersect_mask = fp1*fp2\n",
    "    union_mask = fp1 + fp2\n",
    "    union_mask = map_mask(union_mask, {1:1,2:1})\n",
    "\n",
    "    intersect_mask = intersect_mask.astype(np.int64)\n",
    "    union_mask = union_mask.astype(np.int64)\n",
    "    \n",
    "    if sum(union_mask.flatten()) > 0:    \n",
    "        # IOU = sum(intersect_mask.flatten())/sum(union_mask.flatten())\n",
    "        IOU = sum(intersect_mask.flatten())/sum(union_mask.flatten())\n",
    "    else:\n",
    "        IOU = 0 \n",
    "        \n",
    "    # if (display_images and IOU > 0): # (display_images and IOU == 0)\n",
    "\n",
    "    if display_images == True:\n",
    "        \n",
    "        _buffer = 30\n",
    "        \n",
    "        n_u = lower(u,_buffer)\n",
    "        n_d = upper(d,_buffer)\n",
    "        n_r = upper(r,_buffer)\n",
    "        n_l = lower(l,_buffer)\n",
    "                \n",
    "        print('\\n\\n')  \n",
    "        print('up diff - ', str(n_u-u))\n",
    "        print('down diff - ', str(n_d-d))\n",
    "        print('right diff - ', str(n_r-r))\n",
    "        print('left diff - ', str(n_l-l))\n",
    "        \n",
    "        print('IOU - ', IOU)\n",
    "        \n",
    "        display_arrays([img[n_u:n_d,n_l:n_r,:],\n",
    "                        mask1[n_u:n_d,n_l:n_r],                              \n",
    "                        mask2[n_u:n_d,n_l:n_r]], (20,20)) \n",
    "                    \n",
    "    return IOU\n",
    "\n",
    "\n",
    "\n",
    "def new_calc_polygons(image, threshold=0.5, fig_size=(5,5), plt_fig=False):\n",
    "\n",
    "    new_image = image.copy()\n",
    "    ret, thresh = cv2.threshold(new_image, threshold, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    cont_im = cv2.drawContours(new_image, contours, -1, (0,255,0), 3)\n",
    "    polygons = {}\n",
    "\n",
    "    if cont_im is not None:\n",
    "        \n",
    "        if plt_fig:\n",
    "            plt.figure(figsize = fig_size)\n",
    "            plt.imshow(cont_im)\n",
    "            plt.imshow(thresh)\n",
    "            plt.show()\n",
    "\n",
    "        for poly_index, contour in enumerate(contours, 1):\n",
    "            object_area = cv2.contourArea(contour)\n",
    "            bounding_box = cv2.boundingRect(contour) # x,y,w,h = cv2.boundingRect(contour)\n",
    "\n",
    "           # Create a mask to get the filled polygon pixels\n",
    "            _mask = np.zeros(new_image.shape[:2], dtype=np.uint8)\n",
    "            cv2.fillPoly(_mask, [contour], 1)\n",
    "            # Extract the pixels comprising the polygon\n",
    "            polygon_pixels = np.argwhere(_mask == 1)\n",
    "\n",
    "            coords = []\n",
    "            for point in contour:\n",
    "                coords.append((int(point[0][0]), int(point[0][1])))\n",
    "            polygons[poly_index] = {\"coords\":coords,\n",
    "                                    \"bb\":bounding_box,\n",
    "                                    \"area\": object_area,\n",
    "                                    \"pixels\": [(x, y) for x, y in polygon_pixels]}\n",
    "    return polygons\n",
    "\n",
    "\n",
    "def map_mask(mask, mapping_dict):\n",
    "#     new__mask = mask.copy()\n",
    "    new__mask = np.zeros(mask.shape, np.uint8)\n",
    "    for original, new in mapping_dict.items():\n",
    "        iter_indexes = np.where(mask == original)\n",
    "        new__mask[iter_indexes[0], iter_indexes[1]] = new\n",
    "    return new__mask\n",
    "          \n",
    "\n",
    "def modify_mask(mask, mapping_mask, mapping_dict):\n",
    "    new_mask = mask.copy()    \n",
    "    for original, new in mapping_dict.items():\n",
    "        iter_indexes = np.where(mapping_mask == original)\n",
    "        new_mask[iter_indexes[0], iter_indexes[1]] = new\n",
    "    return new_mask\n",
    "\n",
    "\n",
    "def display_arrays(display_list, figure_size = (20,20), titles = None,\n",
    "                   plt_fig = True, savefig_pth = None):    \n",
    "    plt.figure(figsize=figure_size)  \n",
    "    try:  \n",
    "        for i in range(len(display_list)):\n",
    "            plt.subplot(1, len(display_list), i+1)\n",
    "            plt.imshow((display_list[i]))\n",
    "            plt.axis('off')\n",
    "            if titles != None:\n",
    "                plt.title(titles[i])\n",
    "    except:\n",
    "        hello_there = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = np.load(\"new_sam_arrays.npz\")\n",
    "footprint = np_data[\"footprint\"]\n",
    "tarp = np_data[\"tarp\"]\n",
    "ground_tarp = np_data[\"ground_tarp\"]\n",
    "img = np_data[\"img\"]\n",
    "result = np_data[\"result\"]\n",
    "\n",
    "pred_logits = torch.load(\"sam_logits.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_US_tarp_Apr_25_post(prediction, blue_roof_mask = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    model classes\n",
    "    1 - tarp & insulation on roof\n",
    "    2 - tarp on the ground\n",
    "    3 - blue roof\n",
    "    4 - ignore (out of AOI)\n",
    "    \"\"\"\n",
    "\n",
    "    if blue_roof_mask is not None:\n",
    "        prediction = modify_mask(prediction, blue_roof_mask, {2:2, 3:3})\n",
    "\n",
    "    combined_mask = map_mask(prediction, {1:1,2:1,3:1})\n",
    "    post_pred = prediction.copy()\n",
    "\n",
    "    polygons = new_calc_polygons(combined_mask,\n",
    "                                 0.5,\n",
    "                                 fig_size=None,\n",
    "                                 plt_fig=False)\n",
    "    \n",
    "    for poly, poly_dict in polygons.items():        \n",
    "\n",
    "        poly_indexes = (np.array([coords[0] for coords in poly_dict['pixels']]),\n",
    "                        np.array([coords[1] for coords in poly_dict['pixels']]))      \n",
    "        \n",
    "        poly_pred_class = prediction[poly_indexes[0], poly_indexes[1]]\n",
    "\n",
    "        roof_tarp_pixel_count = len(np.where(poly_pred_class == 1)[0])\n",
    "        ground_tarp_pixels_count = len(np.where(poly_pred_class == 2)[0])\n",
    "        blue_roof_pixels_count = len(np.where(poly_pred_class == 3)[0])\n",
    "        background_pixels_count = len(np.where(poly_pred_class == 0)[0])\n",
    "\n",
    "        # if roof_tarp_pixel_count < 0.5 * (roof_tarp_pixel_count + ground_tarp_pixels_count + blue_roof_pixels_count):\n",
    "        if blue_roof_pixels_count > 0.1 * (roof_tarp_pixel_count + ground_tarp_pixels_count + blue_roof_pixels_count):\n",
    "            post_pred[poly_indexes[0], poly_indexes[1]] = 5\n",
    "            \n",
    "        elif ground_tarp_pixels_count > 0.1 * (roof_tarp_pixel_count + ground_tarp_pixels_count + blue_roof_pixels_count):\n",
    "            post_pred[poly_indexes[0], poly_indexes[1]] = 5\n",
    "\n",
    "        elif roof_tarp_pixel_count < 0.3 *(roof_tarp_pixel_count + background_pixels_count):\n",
    "            post_pred[poly_indexes[0], poly_indexes[1]] = 0\n",
    "\n",
    "        post_pred = modify_mask(post_pred, blue_roof_mask, {2:2, 3:3})\n",
    "\n",
    "    return post_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAM_predict(image, input_points, input_labels):\n",
    "\n",
    "    predictor.set_image(image)\n",
    "    \n",
    "    masks, scores, logits = predictor.predict(\n",
    "    point_coords=input_points,\n",
    "    point_labels=input_labels,\n",
    "    multimask_output=True,\n",
    "    )\n",
    "\n",
    "    return masks, scores, logits\n",
    "\n",
    "\n",
    "\n",
    "def plot_connected_components(binary_mask):    \n",
    "\n",
    "    # Find connected components\n",
    "    labeled_mask = measure.label(binary_mask, connectivity=2)  # Use 4-connectivity (2D)\n",
    "    print(np.unique(labeled_mask.flatten()))\n",
    "\n",
    "    # Display the original binary mask and labeled mask\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 20))\n",
    "    axes[0].imshow(binary_mask, cmap='gray')\n",
    "    axes[0].set_title('Binary Mask')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(labeled_mask, cmap='nipy_spectral')  # Use a color map for visualization\n",
    "    axes[1].set_title('Labeled Components')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def display_SAM_prediction(image, masks, scores, input_points, input_labels):\n",
    "   \n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(image)\n",
    "        show_mask(mask, plt.gca())\n",
    "        show_points(input_points, input_labels, plt.gca())\n",
    "        plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "        plt.axis('off')\n",
    "        plt.show()  \n",
    "\n",
    "\n",
    "inference_img_size = 2048\n",
    "upper = lambda x, buffer: min(x+buffer, inference_img_size)\n",
    "lower = lambda x, buffer: max(0, x-buffer)\n",
    "\n",
    "\n",
    "# def calc_instance_intersection(labeled_mask, unlabeled_mask, mapping = None):\n",
    "    \n",
    "#     if mapping != None:\n",
    "#         unlabeled_mask = map_mask(unlabeled_mask, mapping)\n",
    "\n",
    "#     remaining_labels_mask = unlabeled_mask*labeled_mask\n",
    "#     return np.unique(remaining_labels_mask.flatten())\n",
    "\n",
    "\n",
    "def check_if_high_conf_poly(labeled_mask, componenet_index, prediction_logits):\n",
    "\n",
    "    pxl_indx = np.where(labeled_mask == componenet_index)\n",
    "    pxl_confidence = prediction_logits[1,pxl_indx[0],pxl_indx[1]].cpu().detach().numpy()\n",
    "    pxl_test = (pxl_confidence > 0.38).astype(np.int32)\n",
    "    \n",
    "    if sum(pxl_test) > 0.5*len(pxl_test):\n",
    "        poly_high_conf = True        \n",
    "    else:\n",
    "        poly_high_conf = False\n",
    "\n",
    "    return poly_high_conf, pxl_indx, pxl_confidence\n",
    "    \n",
    "\n",
    "def find_poly_corr_with_sam(pxl_indx, img, tarp_mask, format_img = False):\n",
    "        \n",
    "    pred_u = min(pxl_indx[0])\n",
    "    pred_d = max(pxl_indx[0])\n",
    "    pred_l = min(pxl_indx[1])\n",
    "    pred_r = max(pxl_indx[1])\n",
    "\n",
    "    buffer = 100\n",
    "    u,d,= lower(pred_u,buffer), upper(pred_d,buffer)       \n",
    "    l,r = lower(pred_l,buffer), upper(pred_r,buffer)\n",
    "\n",
    "    input_points = np.array([[pxl_indx[1][i]-l, pxl_indx[0][i]-u] for i in range(len(pxl_indx[0]))])\n",
    "    input_labels = np.array([1]*len(input_points))\n",
    "\n",
    "    img_patch = img[u:d,l:r] \n",
    "\n",
    "    if format_img == True:     \n",
    "        norm_img_patch = np.clip(img_patch * 255, 0, 255)          \n",
    "        img_patch = norm_img_patch.astype(np.uint8) # Convert to uint8\n",
    "\n",
    "    masks, scores, logits = SAM_predict(img_patch, input_points, input_labels)\n",
    "    max_index = np.argmax(scores)\n",
    "    \n",
    "    sam_pxl_indx = np.where(masks[max_index] == True)\n",
    "\n",
    "    sam_u = min(sam_pxl_indx[0])+u\n",
    "    sam_d = max(sam_pxl_indx[0])+u\n",
    "    sam_l = min(sam_pxl_indx[1])+l\n",
    "    sam_r = max(sam_pxl_indx[1])+l\n",
    "\n",
    "    iou_u = min(pred_u, sam_u) \n",
    "    iou_d = max(pred_d, sam_d) \n",
    "    iou_l = min(pred_l, sam_l) \n",
    "    iou_r = max(pred_r, sam_r) \n",
    "\n",
    "    bb = iou_l-l, iou_u-u, iou_r-iou_l, iou_d-iou_u\n",
    "    \n",
    "    # display_arrays([masks[max_index].astype(np.int32),\n",
    "    #                         tarp_mask[u:d,l:r]])\n",
    "\n",
    "    IOU = calc_IOU(bb, img_patch, masks[max_index].astype(np.int32),\n",
    "                        tarp_mask[u:d,l:r], False) \n",
    "    \n",
    "    return (\n",
    "        IOU, img_patch, masks, scores, input_points, input_labels, \n",
    "        bb, max_index, pred_d, pred_l, pred_r, pred_u , d, l, r, u\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_post_process(img, original_tarp_mask, ground_tarp_mask, footprint_mask, pred_logits, display_results = False):\n",
    "\n",
    "\n",
    "    prediction_mask = local_US_tarp_Apr_25_post(original_tarp_mask, ground_tarp_mask)\n",
    "\n",
    "\n",
    "    prediction_logits = torch.softmax(pred_logits, dim=0)\n",
    "    \n",
    "    # Convert to numpy and permute dimensions if necessary\n",
    "    # Convert from [C, H, W] to [H, W, C]   \n",
    "    image_to_display = prediction_logits[0:3,:,:].permute(1, 2, 0)   \n",
    "    image_to_display = image_to_display.cpu().detach().numpy()\n",
    "\n",
    "    if image_to_display.dtype != 'float32':\n",
    "        image_to_display = image_to_display.astype('float32')\n",
    "\n",
    "    tarp_mask = map_mask(prediction_mask, {1:1})\n",
    "\n",
    "    tarp_labeled_mask = measure.label(tarp_mask, connectivity=2)\n",
    "   \n",
    "    thin_tarp_mask = np.uint8(skeletonize(tarp_mask))\n",
    "\n",
    "    assert len(np.unique(thin_tarp_mask.flatten())) == 2\n",
    "\n",
    "    thin_tarp_indexes = np.where(thin_tarp_mask == 1)\n",
    "\n",
    "    assert 0 not in np.unique(tarp_labeled_mask[thin_tarp_indexes[0],thin_tarp_indexes[1]].flatten())\n",
    "\n",
    "    labeled_mask = thin_tarp_mask * tarp_labeled_mask\n",
    "    tarp_component_indexes = np.unique(labeled_mask.flatten()).tolist()\n",
    "    tarp_component_indexes.pop(0) \n",
    "\n",
    "    img_patching_arr = np.zeros(prediction_mask.shape, np.uint8)\n",
    "\n",
    "    buffer = 100    \n",
    "    poly_label_mapping = {}\n",
    "\n",
    "    \n",
    "    for componenet_index in tarp_component_indexes:        \n",
    "\n",
    "        if componenet_index in poly_label_mapping:\n",
    "            continue\n",
    "\n",
    "        poly_high_conf, pxl_indx, pxl_confidence = check_if_high_conf_poly(labeled_mask,\n",
    "                                                                           componenet_index,\n",
    "                                                                           prediction_logits)\n",
    "        if poly_high_conf == True:\n",
    "            poly_label_mapping[componenet_index] = 1\n",
    "        else:\n",
    "            poly_label_mapping[componenet_index] = 6\n",
    "\n",
    "        pred_u = min(pxl_indx[0])\n",
    "        pred_d = max(pxl_indx[0])\n",
    "        pred_l = min(pxl_indx[1])\n",
    "        pred_r = max(pxl_indx[1])\n",
    "\n",
    "        u,d,= lower(pred_u,buffer), upper(pred_d,buffer)       \n",
    "        l,r = lower(pred_l,buffer), upper(pred_r,buffer)\n",
    "\n",
    "        img_patching_arr[u:d,l:r] = 1\n",
    "\n",
    "\n",
    "    patching_labeled_mask = measure.label(img_patching_arr, connectivity=2)\n",
    "    patching_component_indexes = np.unique(patching_labeled_mask.flatten()).tolist()\n",
    "    patching_component_indexes.pop(0) \n",
    "    img_patch_dict = {}\n",
    "\n",
    "    for patch_component_indx in patching_component_indexes:\n",
    "\n",
    "        patching_pxl_indx = np.where(patching_labeled_mask == patch_component_indx)\n",
    "        patch_u = min(patching_pxl_indx[0])\n",
    "        patch_d = max(patching_pxl_indx[0])\n",
    "        patch_l = min(patching_pxl_indx[1])\n",
    "        patch_r = max(patching_pxl_indx[1])\n",
    "\n",
    "        img_patch = img[patch_u:patch_d,patch_l:patch_r]      \n",
    "        norm_img_patch = np.clip(img_patch * 255, 0, 255)          \n",
    "        img_patch = norm_img_patch.astype(np.uint8)\n",
    "\n",
    "        img_patch_dict[(patch_u, patch_d, patch_l, patch_r)] = img_patch\n",
    "\n",
    "    \n",
    "    footprint_mask = map_mask(footprint_mask, {1:10,3:10,4:10,5:10})  # previous - {1:1,2:1,3:1,4:1,5:1}\n",
    "    \n",
    "    return_mask = map_mask(tarp_labeled_mask, poly_label_mapping)\n",
    "    remaining_classes_mask = map_mask(prediction_mask, {2:2,3:3,4:4,5:5})\n",
    "    return_mask = return_mask + remaining_classes_mask + footprint_mask\n",
    "\n",
    "    \n",
    "    return return_mask, img_patch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_post_process(mask, img_patch_dict):\n",
    "\n",
    "    img = np.zeros((mask.shape[0],mask.shape[1],3), np.uint8)\n",
    "\n",
    "    for patch_key, patch_img in img_patch_dict.items():\n",
    "        patch_u = patch_key[0]\n",
    "        patch_d = patch_key[1]\n",
    "        patch_l = patch_key[2]\n",
    "        patch_r = patch_key[3]\n",
    "        img[patch_u:patch_d,patch_l:patch_r] = patch_img\n",
    "        \n",
    "\n",
    "    footprint_mask = np.zeros(mask.shape, np.uint8)\n",
    "\n",
    "    fp_indexes = np.where(mask >= 10)\n",
    "\n",
    "    footprint_mask[fp_indexes[0],fp_indexes[1]]=1\n",
    "\n",
    "    prediction_mask = mask - 10*footprint_mask\n",
    "\n",
    "    tarp_mask = map_mask(prediction_mask, {6:1})\n",
    "    \n",
    "    tarp_labeled_mask = measure.label(tarp_mask, connectivity=2)\n",
    "   \n",
    "    thin_tarp_mask = np.uint8(skeletonize(tarp_mask))\n",
    "\n",
    "    assert len(np.unique(thin_tarp_mask.flatten())) == 2\n",
    "\n",
    "    thin_tarp_indexes = np.where(thin_tarp_mask == 1)\n",
    "\n",
    "    assert 0 not in np.unique(tarp_labeled_mask[thin_tarp_indexes[0],thin_tarp_indexes[1]].flatten())\n",
    "\n",
    "    labeled_mask = thin_tarp_mask * tarp_labeled_mask\n",
    "    num_components = len(np.unique(labeled_mask.flatten()))\n",
    "     \n",
    "    labeled_fp_mask = measure.label(footprint_mask, connectivity=2)\n",
    "    fp_num_componenets = len(np.unique(labeled_fp_mask.flatten()))\n",
    "    \n",
    "    if num_components == 1 or fp_num_componenets == 1:\n",
    "        return prediction_mask\n",
    "    \n",
    "    buffer = 100\n",
    "    poly_label_mapping = {}\n",
    "\n",
    "    for fp_index in range(fp_num_componenets):\n",
    "        \n",
    "        fp_pxl_indx = np.where(labeled_fp_mask == fp_index)\n",
    "        labeled_mask_in_fp = labeled_mask[fp_pxl_indx[0],fp_pxl_indx[1]].flatten()\n",
    "        poly_indexes_inside_fp = np.unique(labeled_mask_in_fp)\n",
    "        poly_indexes_inside_fp = poly_indexes_inside_fp.tolist()\n",
    "        poly_indexes_inside_fp.pop(0) \n",
    "\n",
    "        dict_poly_inside_fp = {x:np.count_nonzero(labeled_mask_in_fp == x) for x in poly_indexes_inside_fp}\n",
    "        # acsending_dict_poly_inside_fp = dict(sorted(dict_poly_inside_fp.items(), key=lambda item: item[1]))\n",
    "        decsending_dict_desc = dict(sorted(dict_poly_inside_fp.items(), key=lambda item: item[1], reverse=True))\n",
    "      \n",
    "        # if fp_index == 0:  \n",
    "        #     individual_poly_processing = True\n",
    "        # else:\n",
    "        #     individual_poly_processing = False\n",
    "\n",
    "        # individual_poly_processing = True\n",
    "\n",
    "        for componenet_index in list(decsending_dict_desc.keys()):        \n",
    "\n",
    "            if componenet_index in poly_label_mapping:\n",
    "                continue\n",
    "\n",
    "            pxl_indx = np.where(labeled_mask == componenet_index)\n",
    "                    \n",
    "\n",
    "            (   IOU, img_patch, masks, scores, input_points, \n",
    "                input_labels, bb, max_index, pred_d, \n",
    "                pred_l, pred_r, pred_u, d, l, r, u\n",
    "            ) = find_poly_corr_with_sam(pxl_indx, img, tarp_mask, False)\n",
    "\n",
    "            if IOU < 0.3:        \n",
    "                # print(f'{u} {d} {l} {r}')\n",
    "                poly_label_mapping[componenet_index] = 0\n",
    "            elif IOU < 0.7:\n",
    "                # print(f'light filter -  {u} {d} {l} {r}')\n",
    "                poly_label_mapping[componenet_index] = 0\n",
    "            if IOU >= 0.7:\n",
    "                # print(f'strong filter -  {u} {d} {l} {r}')\n",
    "                poly_label_mapping[componenet_index] = 1\n",
    "\n",
    "\n",
    "    final_mask = map_mask(tarp_labeled_mask, poly_label_mapping)\n",
    "    remaining_classes_mask = map_mask(prediction_mask, {1:1,2:2,3:3,4:4,5:5})\n",
    "    final_mask = final_mask + remaining_classes_mask\n",
    "\n",
    "    \n",
    "    return final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "return_mask, img_patch_dict = first_post_process(img, tarp, ground_tarp, footprint, pred_logits, display_results = False)\n",
    "\n",
    "final_tarp = second_post_process(return_mask, img_patch_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 5]\n",
      "14422\n",
      "[0 1 2 5]\n",
      "14422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_result = map_mask(result, {1:1,2:2,3:3,4:4,5:5})\n",
    "\n",
    "# print(np.unique(final_tarp.flatten()))\n",
    "# print(sum(final_tarp.flatten()))\n",
    "\n",
    "# print(np.unique(new_result.flatten()))\n",
    "# print(sum(new_result.flatten()))\n",
    "\n",
    "# np.array_equal(new_result, final_tarp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
